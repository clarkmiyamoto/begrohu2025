\section{Overview}
Jean R\'emi King is a research at Meta Brain. In his talk he'll be going over:
\begin{enumerate}
	\item The discovery of neural codes.
	\item Evidence of convergence.
	\item Coding compositional structures.
\end{enumerate}
As an overview, the brain is obviously why humans are able to reason about the world. So the question becomes what are the \textit{exact} mechanisms which allow for reasoning? In King's research they often use an MRI and to image the brain while a participants is being shown stimuli. Experimentaly, you can show that (in a spatial sense) the brain reacting to stimuli respects locality \& hierarchy: that words go here and faces go there, and orientations of faces are within the faces section, and slightly to the side is if the face is smiling or not.\\
\\
How does machine learning come into play? Well obviously use ML to help us decode what the brain is doing (so you can perform a bayesian inference on, given brain activity, ask what is this person looking at?). If you want to see these visualizations, see Ozcelik \& van Rullen (2022), and then say wow.

\begin{definition}
	[Representation (according to King)] A representation is linearly readable information. That is if there is linear map $f$ which $\hat Y = f(X)$  approximates $Y$ quite well, then $X$ is a representation of $Y$.
\end{definition}
A very interesting application of keeping representations restricted to linear maps is attmempting to perform linear regression from brain activity to various encoders (i.e. CNN, word2vec, and ChatGPT). You can do an experiment where you map how these perform as a function of time after exposed to a word and the location in the brain, and you recover what you expect...









